{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "END2.0_Assignment_9_BLEU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vW1NZgLnSQX",
        "outputId": "133525e4-8c77-4055-b049-ef58a3821b97"
      },
      "source": [
        "# install huggingface transformers \n",
        "!pip install transformers==3.0.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/25/89050e69ed53c2a3b7f8c67844b3c8339c1192612ba89a172cf85b298948/transformers-3.0.1-py3-none-any.whl (757kB)\n",
            "\r\u001b[K     |▍                               | 10kB 23.3MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 20.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 16.7MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 15.1MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 7.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 8.7MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 9.1MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81kB 9.4MB/s eta 0:00:01\r\u001b[K     |████                            | 92kB 9.9MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 8.1MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 133kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 153kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 163kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 174kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 184kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 194kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 204kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 225kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 235kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 245kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 256kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 266kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 276kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 286kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 296kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 307kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 317kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 327kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 337kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 348kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 358kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 368kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 378kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 389kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 399kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 409kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 419kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 430kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 440kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 450kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 460kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 471kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 481kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 491kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 501kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 512kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 522kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 532kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 542kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 552kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 563kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 573kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 583kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 593kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 604kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 614kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 624kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 634kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 645kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 655kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 665kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 675kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 686kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 696kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 706kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 716kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 727kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 737kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 747kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 757kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.1) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.1) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.1) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.1) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.1) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 27.2MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 37.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.1) (2.23.0)\n",
            "Collecting tokenizers==0.8.0-rc4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/82/0e82a95bd9db2b32569500cc1bb47aa7c4e0f57aa5e35cceba414096917b/tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 33.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.1) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.1) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.1) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.1) (1.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.1) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.1) (1.24.3)\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.45 sentencepiece-0.1.96 tokenizers-0.8.0rc4 transformers-3.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOkGh8njnm7D",
        "outputId": "0f367017-f264-478b-a8e9-1e9d83a16b29"
      },
      "source": [
        "# install bert score\n",
        "!pip install bert_score==0.3.4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert_score==0.3.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/74/410f2cb80ea7cc9f112de55a7cf63f0880d2db963375b73a557d0746b5f1/bert_score-0.3.4-py3-none-any.whl (52kB)\n",
            "\r\u001b[K     |██████▎                         | 10kB 18.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 20kB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 30kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 40kB 13.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 51kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bert_score==0.3.4) (1.19.5)\n",
            "Requirement already satisfied: transformers>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from bert_score==0.3.4) (3.0.1)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.7/dist-packages (from bert_score==0.3.4) (4.41.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from bert_score==0.3.4) (3.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bert_score==0.3.4) (2.23.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from bert_score==0.3.4) (1.9.0+cu102)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from bert_score==0.3.4) (1.1.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=2.2.0->bert_score==0.3.4) (0.0.45)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.2.0->bert_score==0.3.4) (0.1.96)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.2.0->bert_score==0.3.4) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.2.0->bert_score==0.3.4) (0.8.0rc4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=2.2.0->bert_score==0.3.4) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=2.2.0->bert_score==0.3.4) (3.0.12)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert_score==0.3.4) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert_score==0.3.4) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert_score==0.3.4) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert_score==0.3.4) (0.10.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score==0.3.4) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score==0.3.4) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score==0.3.4) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score==0.3.4) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->bert_score==0.3.4) (3.7.4.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert_score==0.3.4) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.2.0->bert_score==0.3.4) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.2.0->bert_score==0.3.4) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.2.0->bert_score==0.3.4) (1.0.1)\n",
            "Installing collected packages: bert-score\n",
            "Successfully installed bert-score-0.3.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guaINckSRld8"
      },
      "source": [
        "#import all the necessary packages\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.legacy.datasets import Multi30k\n",
        "from torchtext.legacy.data import Field, BucketIterator\n",
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "from bert_score import score\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICHikx82Rty5"
      },
      "source": [
        "# Then set a random seed for deterministic results/reproducability\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIaE1DUghreR",
        "outputId": "e13482de-5d16-4cf0-ff9e-eb0d1f5ecde6"
      },
      "source": [
        "!python -m spacy download en --quiet\n",
        "!python -m spacy download de --quiet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 7.9MB/s \n",
            "\u001b[?25h  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHhtbFyMRt-Q"
      },
      "source": [
        "# Instantiate our German and English spaCy models.\n",
        "\n",
        "spacy_de = spacy.load('de')   \n",
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRMxkUk7RuDb"
      },
      "source": [
        "def tokenize_de(text):\n",
        "    \"\"\"\n",
        "    Tokenizes German text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNOtrXEjRuNG"
      },
      "source": [
        "# Create our fields to process our data. \n",
        "# This will append the \"start of sentence\" and \"end of sentence\" tokens as well as converting all words to lowercase\n",
        "\n",
        "SRC = Field(tokenize=tokenize_de, \n",
        "            init_token='<sos>', \n",
        "            eos_token='<eos>', \n",
        "            lower=True)\n",
        "\n",
        "TRG = Field(tokenize = tokenize_en, \n",
        "            init_token='<sos>', \n",
        "            eos_token='<eos>', \n",
        "            lower=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n4PhRK0RuRL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bd39626-ef34-4e6e-c091-dc6ef3c4788c"
      },
      "source": [
        "# Load our data.\n",
        "\n",
        "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), \n",
        "                                                    fields = (SRC, TRG))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading training.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:01<00:00, 1.09MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading validation.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 167kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading mmt_task1_test2016.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 165kB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1cbj_jARuaS"
      },
      "source": [
        "# create our vocabulary, converting all tokens appearing less than twice into <unk> tokens.\n",
        "SRC.build_vocab(train_data, min_freq = 2)\n",
        "TRG.build_vocab(train_data, min_freq = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUwRwmgVRufD"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpD0wpWQRujg"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqG73qW1Runp"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim) #no dropout as only one layer!\n",
        "        \n",
        "        self.rnn = nn.GRU(emb_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        \n",
        "        #embedded = [src len, batch size, emb dim]\n",
        "        \n",
        "        outputs, hidden = self.rnn(embedded) #no cell state!\n",
        "        \n",
        "        #outputs = [src len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #outputs are always from the top hidden layer\n",
        "        \n",
        "        return hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYRnDPBhRurn"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        self.output_dim = output_dim\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU(emb_dim + hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_out = nn.Linear(emb_dim + hid_dim * 2, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, context):\n",
        "        \n",
        "        #input = [batch size]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #context = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #n layers and n directions in the decoder will both always be 1, therefore:\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        #context = [1, batch size, hid dim]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "                \n",
        "        emb_con = torch.cat((embedded, context), dim = 2)\n",
        "            \n",
        "        #emb_con = [1, batch size, emb dim + hid dim]\n",
        "            \n",
        "        output, hidden = self.rnn(emb_con, hidden)\n",
        "        \n",
        "        #output = [seq len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #seq len, n layers and n directions will always be 1 in the decoder, therefore:\n",
        "        #output = [1, batch size, hid dim]\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        \n",
        "        output = torch.cat((embedded.squeeze(0), hidden.squeeze(0), context.squeeze(0)), \n",
        "                           dim = 1)\n",
        "        \n",
        "        #output = [batch size, emb dim + hid dim * 2]\n",
        "        \n",
        "        prediction = self.fc_out(output)\n",
        "        \n",
        "        #prediction = [batch size, output dim]\n",
        "        return prediction,hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlCWbPMQRuwc"
      },
      "source": [
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "        \n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #last hidden state of the encoder is the context\n",
        "        context = self.encoder(src)\n",
        "        \n",
        "        #context also used as the initial hidden state of the decoder\n",
        "        hidden = context\n",
        "        \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "        \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden state and the context state\n",
        "            #receive output tensor (predictions) and new hidden state\n",
        "            output, hidden = self.decoder(input, hidden, context)\n",
        "            \n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It7SaDJ0Ruz3"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, DEC_DROPOUT)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R75TYLERu3y"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, DEC_DROPOUT)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xZaYpEYRu8J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d32d8498-b2c7-4a5a-bf34-8f811193ca72"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        \n",
        "model.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(7855, 256)\n",
              "    (rnn): GRU(256, 512)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(5893, 256)\n",
              "    (rnn): GRU(768, 512)\n",
              "    (fc_out): Linear(in_features=1280, out_features=5893, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msGQCnc7RvCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb0366ad-4c93-480b-8bb4-34d81962bf47"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 14,220,293 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKafAIl8mRhj"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EklPXgEEmU3k"
      },
      "source": [
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B9TspMamXp5"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    b_score = 0 \n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, trg)\n",
        "        \n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "\n",
        "        final = torch.argmax(output, dim = 2).permute(1,0).reshape(-1)\n",
        "        trg_t = trg.permute(1,0).reshape(-1)\n",
        "\n",
        "        trg_text = [TRG.vocab.itos[i] for i in trg_t]\n",
        "        fnl_text = [TRG.vocab.itos[i] for i in final]\n",
        "\n",
        "        b_score = bleu_score(fnl_text, trg_text, max_n=1, weights=[1])\n",
        "        # end of bleu score\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        \n",
        "        #trg = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        b_score += b_score\n",
        "        \n",
        "        \n",
        "    return epoch_loss / len(iterator), b_score/len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhwoAXC_nJWG"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    b_score = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "             # start of bleu score\n",
        "            final = torch.argmax(output, dim = 2).permute(1,0).reshape(-1)\n",
        "            trg_t = trg.permute(1,0).reshape(-1)\n",
        "\n",
        "            trg_text = [TRG.vocab.itos[i] for i in trg_t]\n",
        "            fnl_text = [TRG.vocab.itos[i] for i in final]\n",
        "            # print(trg_text)\n",
        "            # print('-'*90)\n",
        "            # print(fnl_text)\n",
        "            # print('-'*90)\n",
        "\n",
        "            b_score = bleu_score(fnl_text, trg_text, max_n=1, weights=[1])\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            \n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            # print(output,output.shape)\n",
        "            # print('-'*90)\n",
        "            # print(trg,trg.shape)\n",
        "            # print('-'*90)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            b_score += b_score\n",
        "            \n",
        "            \n",
        "    return epoch_loss / len(iterator), b_score/len(iterator), "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iamKikGnOKX"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsLPMVeDnrkJ",
        "outputId": "33a5ee27-8693-4d0c-a54a-d440550f97bd"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss,train_b_score = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss,valid_b_score= evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    # if valid_loss < best_valid_loss:\n",
        "    #     best_valid_loss = valid_loss\n",
        "    #     torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f} | Train Bleu Score: {train_b_score:.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f} | Val. Bleu Score: {valid_b_score:.3f}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 2m 0s\n",
            "\tTrain Loss: 5.051 | Train PPL: 156.176 | Train Bleu Score: 0.003\n",
            "\t Val. Loss: 5.124 |  Val. PPL: 167.925 | Val. Bleu Score: 0.081\n",
            "Epoch: 02 | Time: 2m 1s\n",
            "\tTrain Loss: 4.386 | Train PPL:  80.355 | Train Bleu Score: 0.003\n",
            "\t Val. Loss: 5.251 |  Val. PPL: 190.726 | Val. Bleu Score: 0.091\n",
            "Epoch: 03 | Time: 2m 2s\n",
            "\tTrain Loss: 4.087 | Train PPL:  59.577 | Train Bleu Score: 0.004\n",
            "\t Val. Loss: 4.720 |  Val. PPL: 112.124 | Val. Bleu Score: 0.091\n",
            "Epoch: 04 | Time: 2m 4s\n",
            "\tTrain Loss: 3.758 | Train PPL:  42.875 | Train Bleu Score: 0.004\n",
            "\t Val. Loss: 4.447 |  Val. PPL:  85.389 | Val. Bleu Score: 0.091\n",
            "Epoch: 05 | Time: 2m 5s\n",
            "\tTrain Loss: 3.441 | Train PPL:  31.215 | Train Bleu Score: 0.003\n",
            "\t Val. Loss: 4.174 |  Val. PPL:  64.997 | Val. Bleu Score: 0.092\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}